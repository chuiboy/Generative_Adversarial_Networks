{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Adversarial Network\n",
    "___\n",
    "#### Description:\n",
    "This notebook for the most part follows an example from the Udemy course \"Complete Guide to TensorFlow for Deep Learning with Python\" section on GANs. This GAN is fed images from the MNIST dataset to generate new images that resemble those from the dataset. It works by having a generator network and a discriminator network compete with one another. The generator is tasked to generate new images and it is the discriminators job to tell if the generated image is fake or real.\n",
    "___\n",
    "#### Dataset:\n",
    "\n",
    "The MNIST dataset of handwritten numbers is used.\n",
    "___\n",
    "#### References:\n",
    "Aside from the Udemy course, I looked at https://github.com/soumith/ganhacks for ideas on how to improve training performance, and I also read  https://deeplearning4j.org/generative-adversarial-network for more information on GANs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../Datasets/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting ../Datasets/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting ../Datasets/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../Datasets/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "X train: (55000, 784)\n",
      "X test: (10000, 784)\n",
      "y train: (55000,)\n",
      "y test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Import the dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Read the dataset\n",
    "dataset = input_data.read_data_sets('../Datasets/MNIST/')\n",
    "\n",
    "# Printing the dataset shape\n",
    "print('X train:', dataset.train.images.shape)\n",
    "print('X test:', dataset.test.images.shape)\n",
    "print('y train:', dataset.train.labels.shape)\n",
    "print('y test:', dataset.test.labels.shape)\n",
    "\n",
    "# NOTE: Pixel values have already been preprocessed to lie between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a204f98>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15bfa898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display a random training example\n",
    "rand_idx = np.random.randint(dataset.train.num_examples)\n",
    "plt.imshow(dataset.train.images[rand_idx].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator function\n",
    "def generator(z, reuse=None):\n",
    "    with tf.variable_scope('gen', reuse=reuse):\n",
    "        hidden1 = tf.nn.leaky_relu(tf.layers.dense(inputs=z, units=128), alpha=0.2)\n",
    "        hidden2 = tf.nn.leaky_relu(tf.layers.dense(inputs=hidden1, units=128), alpha=0.2)\n",
    "        output = tf.layers.dense(inputs=hidden2, units=784, activation=tf.nn.tanh)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator function\n",
    "def discriminator(X, reuse=None):\n",
    "    with tf.variable_scope('dis', reuse=reuse):\n",
    "        hidden1 = tf.nn.leaky_relu(tf.layers.dense(inputs=X, units=128), alpha=0.2)\n",
    "        hidden2 = tf.nn.leaky_relu(tf.layers.dense(inputs=hidden1, units=128), alpha=0.2)\n",
    "        logits = tf.layers.dense(inputs=hidden2, units=1)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholders\n",
    "real_images = tf.placeholder(tf.float32, [None, 784])\n",
    "z = tf.placeholder(tf.float32, [None, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct generator graph\n",
    "G = generator(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct discriminator graph and combined graph\n",
    "D_logits_real = discriminator(real_images)\n",
    "D_logits_fake = discriminator(G, reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def loss_func(logits, labels):\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator loss with smoothing\n",
    "D_real_loss = loss_func(D_logits_real, tf.random_uniform(tf.shape(D_logits_real), minval=0.7, maxval=1.2))\n",
    "D_fake_loss = loss_func(D_logits_fake, tf.random_uniform(tf.shape(D_logits_fake), minval=0.0, maxval=0.3))\n",
    "\n",
    "D_loss = (D_real_loss + D_fake_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator loss with smoothing\n",
    "G_loss = loss_func(D_logits_fake, tf.random_uniform(tf.shape(D_logits_fake), minval=0.7, maxval=1.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of trainable varibles\n",
    "tvars = tf.trainable_variables()\n",
    "d_vars = [var for var in tvars if 'dis' in var.name]\n",
    "g_vars = [var for var in tvars if 'gen' in var.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dis/dense/kernel:0' shape=(784, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'dis/dense/bias:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'dis/dense_1/kernel:0' shape=(128, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'dis/dense_1/bias:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'dis/dense_2/kernel:0' shape=(128, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'dis/dense_2/bias:0' shape=(1,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect discriminator variables\n",
    "d_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants/Hyperparameters\n",
    "batch_size = 128\n",
    "epochs = 200\n",
    "learning_rate = 2e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer for discriminator\n",
    "D_trainer = tf.train.AdamOptimizer(learning_rate).minimize(D_loss, var_list=d_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer for generator (discriminator weights do not get updated)\n",
    "G_trainer = tf.train.AdamOptimizer(learning_rate).minimize(G_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a saver\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\tD_loss=0.6600810289382935,\tG_loss=1.4707157611846924\n",
      "Epoch 10:\tD_loss=0.8271271586418152,\tG_loss=1.2036936283111572\n",
      "Epoch 20:\tD_loss=1.0006135702133179,\tG_loss=1.2571945190429688\n",
      "Epoch 30:\tD_loss=0.8369283676147461,\tG_loss=1.5662391185760498\n",
      "Epoch 40:\tD_loss=0.9366947412490845,\tG_loss=1.1670918464660645\n",
      "Epoch 50:\tD_loss=0.9845638275146484,\tG_loss=1.0834474563598633\n",
      "Epoch 60:\tD_loss=0.9992818236351013,\tG_loss=1.1366631984710693\n",
      "Epoch 70:\tD_loss=0.9344243407249451,\tG_loss=1.3494305610656738\n",
      "Epoch 80:\tD_loss=1.1038422584533691,\tG_loss=1.1676753759384155\n",
      "Epoch 90:\tD_loss=0.9874786138534546,\tG_loss=1.1857624053955078\n",
      "Epoch 100:\tD_loss=1.0226231813430786,\tG_loss=1.007949948310852\n",
      "Epoch 110:\tD_loss=1.1121187210083008,\tG_loss=1.190567135810852\n",
      "Epoch 120:\tD_loss=1.0080595016479492,\tG_loss=1.2641711235046387\n",
      "Epoch 130:\tD_loss=1.0714389085769653,\tG_loss=1.0290733575820923\n",
      "Epoch 140:\tD_loss=1.0431876182556152,\tG_loss=1.1200950145721436\n",
      "Epoch 150:\tD_loss=1.1082284450531006,\tG_loss=1.2943652868270874\n",
      "Epoch 160:\tD_loss=1.118405818939209,\tG_loss=1.1639652252197266\n",
      "Epoch 170:\tD_loss=1.0528059005737305,\tG_loss=1.27152419090271\n",
      "Epoch 180:\tD_loss=1.0687044858932495,\tG_loss=1.139794111251831\n",
      "Epoch 190:\tD_loss=1.091787338256836,\tG_loss=1.1190263032913208\n"
     ]
    }
   ],
   "source": [
    "# Create a session\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Initialize variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        num_batches = dataset.train.num_examples // batch_size\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            \n",
    "            batch_images, _ = dataset.train.next_batch(batch_size)            \n",
    "            batch_images = batch_images * 2 - 1 # make pixel values between (-1, 1)            \n",
    "            batch_z = np.random.normal(0, 1, size=(batch_size, 100))\n",
    "                \n",
    "            # Training step\n",
    "            sess.run(D_trainer, feed_dict={real_images: batch_images, z: batch_z})\n",
    "            sess.run(G_trainer, feed_dict={z: batch_z})\n",
    "        \n",
    "        # Evaluate loss every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            D_loss_val = D_loss.eval(feed_dict={real_images: batch_images, z: batch_z})\n",
    "            G_loss_val = G_loss.eval(feed_dict={z: batch_z})\n",
    "            print('Epoch {}:\\tD_loss={},\\tG_loss={}'.format(epoch, D_loss_val, G_loss_val))        \n",
    "            \n",
    "            # Save generated images every 10 epochs\n",
    "            sample_z = np.random.normal(0, 1, size=(25, 100))\n",
    "            gen_sample = sess.run(generator(z, reuse=True), feed_dict={z: sample_z})\n",
    "            gen_sample = 0.5 * gen_sample + 0.5 # make pixel values between (0, 1)\n",
    "            \n",
    "            fig, ax = plt.subplots(5, 5)\n",
    "            count = 0\n",
    "            for i in range(5):\n",
    "                for j in range(5):\n",
    "                    ax[i, j].imshow(gen_sample[count].reshape(28, 28), cmap='gray')\n",
    "                    ax[i, j].axis('off')\n",
    "                    count += 1\n",
    "            fig.savefig('images/epoch_%d.png' % epoch)\n",
    "            plt.close()\n",
    "        \n",
    "    # Save the session\n",
    "    saver.save(sess, './gan_session.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
